{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f273c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from lxml import etree\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b140fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"./xml/*.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd30ce6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cf5cd",
   "metadata": {},
   "source": [
    "### Dataset entier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2dbc1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7e03a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_datasets_extraction(language, files_list):    \n",
    "    \n",
    "    all_textes = []\n",
    "    all_arks = []\n",
    "    all_auteurs = []\n",
    "    all_typ = []\n",
    "    all_index = []\n",
    "    \n",
    "    if language == \"co\":\n",
    "        path = '//rubrique[@lan=\"co\"]/'\n",
    "        name = 'corsican'\n",
    "    elif language == \"fr\":\n",
    "        path = '//rubrique[@lan=\"fr\"]/'\n",
    "        name = 'french'\n",
    "    elif language == \"it\":\n",
    "        path = '//rubrique[@lan=\"it\"]/'\n",
    "        name = 'italian'\n",
    "    else:\n",
    "        raise ValueError(\"Non recognized language. Available languages identifiers ==> 'co', 'fr', 'it'.\")\n",
    "    \n",
    "    for xml in files_list:\n",
    "\n",
    "        if re.search(r\"(bpt\\w*)\", xml):\n",
    "            ark = re.search(r\"(bpt\\w*)\", xml).group(1)\n",
    "\n",
    "        tree = etree.parse(xml)\n",
    "\n",
    "        arks = []\n",
    "        textes = []\n",
    "        index = []\n",
    "        typ = []\n",
    "        auteur = []\n",
    "        \n",
    "        for tag in tree.xpath(path + 'texte'):\n",
    "            x = tag.text\n",
    "            x = re.sub(r'\\n', r'', x)\n",
    "            textes.append(x)\n",
    "\n",
    "            arks.append(ark)\n",
    "\n",
    "        for tag in tree.xpath(path + 'auteur'):\n",
    "            x = tag.text\n",
    "            x = re.sub(r'\\n', r'', x)\n",
    "            auteur.append(x)\n",
    "\n",
    "        for tag in tree.xpath(path + 'type'):\n",
    "            x = tag.text\n",
    "            x = re.sub(r'\\n', r'', x)\n",
    "            typ.append(x)\n",
    "\n",
    "        for tag in tree.xpath(path + 'index'):\n",
    "            x = tag.text\n",
    "            x = re.sub(r'\\n', r'', x)\n",
    "            index.append(x)\n",
    "\n",
    "        all_textes.extend(textes)\n",
    "        all_auteurs.extend(auteur)\n",
    "        all_index.extend(index)\n",
    "        all_typ.extend(typ)\n",
    "        all_arks.extend(arks)\n",
    "    \n",
    "    dic = {\"Texts\":all_textes, \"Auteurs\":all_auteurs, \"Type\":all_typ, \"Position\":all_index, \"Arks\":all_arks}\n",
    "    df = pd.DataFrame(dic)\n",
    "    df.to_csv(\"full_\" + name + \"_dataset.tsv\", '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f52e0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2d6cc",
   "metadata": {},
   "source": [
    "### Datasets d'entraÃ®nements et de tests pour le Corse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b5be931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_test_corpus_selection(dataset, language, limit):\n",
    "\n",
    "    if language == \"co\":\n",
    "        name = 'corsican'\n",
    "    elif language == \"fr\":\n",
    "        name = 'french'\n",
    "    elif language == \"it\":\n",
    "        name = 'italian'\n",
    "    else:\n",
    "        raise ValueError(\"Non recognized language. Available languages identifiers ==> 'co', 'fr', 'it'.\")\n",
    "        \n",
    "    df = pd.read_csv(dataset, '\\t')\n",
    "    \n",
    "    df_test = df.iloc[:limit]\n",
    "    df_test = pd.DataFrame(df_test)\n",
    "    df_test.to_csv(\"test_\" + name + \".tsv\", '\\t')\n",
    "    df_train = df.iloc[limit + 1:]\n",
    "    df_train = pd.DataFrame(df_train)\n",
    "    df_train.to_csv(\"train_\" + name + \".tsv\", '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64bce2c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b4f75",
   "metadata": {},
   "source": [
    "### Hapax et duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca5dd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hapax_counter(freq_tokens):\n",
    "    list_hapax = []\n",
    "    for k, v in freq_tokens.items():\n",
    "        if 1 == v:\n",
    "            list_hapax.append(k)\n",
    "    return list_hapax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fcb150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicates_counter(freq_tokens):    \n",
    "    duplicates = []\n",
    "    for k, v in freq_tokens.items():\n",
    "        if 1 < v:\n",
    "            duplicates.append(k)\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af8e9fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1847b",
   "metadata": {},
   "source": [
    "### Document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "982c4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_term_matrix(list_files, language):\n",
    "    \n",
    "    if language == \"co\":\n",
    "        path = '//rubrique[@lan=\"co\"]/'\n",
    "        name = 'corsican'\n",
    "    elif language == \"fr\":\n",
    "        path = '//rubrique[@lan=\"fr\"]/'\n",
    "        name = 'french'\n",
    "    elif language == \"it\":\n",
    "        path = '//rubrique[@lan=\"it\"]/'\n",
    "        name = 'italian'\n",
    "    else:\n",
    "        raise ValueError(\"Non recognized language. Available languages identifiers ==> 'co', 'fr', 'it'.\")\n",
    "    \n",
    "    liste_textes = []\n",
    "    \n",
    "    for xml in list_files:\n",
    "\n",
    "        tree = etree.parse(xml)\n",
    "\n",
    "        textes = []\n",
    "        \n",
    "        for tag in tree.xpath(path + 'texte'):\n",
    "            x = tag.text\n",
    "            x = re.sub(r'\\n', r'', x)\n",
    "            textes.append(x)\n",
    "\n",
    "        liste_textes.extend(textes)    \n",
    "    \n",
    "    tokens = ' '.join(liste_textes)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(tokens)\n",
    "    \n",
    "    frequence = dict(nltk.FreqDist(tokens))\n",
    "    \n",
    "    df = pd.DataFrame(frequence, index=[\"Frequency\"])\n",
    "    df.index.name = \"Word\"\n",
    "    df = df.T\n",
    "    \n",
    "    df.to_csv(\"documentTermMatrix_\" + name + \".tsv\", '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df2f19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf29edf",
   "metadata": {},
   "source": [
    "### Vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38778a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_counter(list_files, language):\n",
    "\n",
    "    if language == \"co\":\n",
    "        path = '//rubrique[@lan=\"co\"]/'\n",
    "        name = 'corsican'\n",
    "    elif language == \"fr\":\n",
    "        path = '//rubrique[@lan=\"fr\"]/'\n",
    "        name = 'french'\n",
    "    elif language == \"it\":\n",
    "        path = '//rubrique[@lan=\"it\"]/'\n",
    "        name = 'italian'\n",
    "    else:\n",
    "        raise ValueError(\"Non recognized language. Available languages identifiers ==> 'co', 'fr', 'it'.\")\n",
    "    \n",
    "    liste_textes = []\n",
    "    \n",
    "    for xml in list_files:\n",
    "\n",
    "        tree = etree.parse(xml)\n",
    "\n",
    "        textes = []\n",
    "        \n",
    "        for tag in tree.xpath(path + 'texte'):\n",
    "            x = tag.text\n",
    "            x = re.sub(r'\\n', r'', x)\n",
    "            textes.append(x)\n",
    "\n",
    "        liste_textes.extend(textes)\n",
    "        \n",
    "    tokens = ' '.join(liste_textes)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(tokens)\n",
    "    \n",
    "    frequence = dict(nltk.FreqDist(tokens))\n",
    "    \n",
    "    hapax = hapax_counter(frequence)\n",
    "    duplicates = duplicates_counter(frequence)\n",
    "    \n",
    "    vocabulary = duplicates + hapax\n",
    "    \n",
    "    with open(\"vocabulary_\" + name + \".txt\", \"w\") as f:\n",
    "        for word in vocabulary:\n",
    "            f.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f834e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ed74a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ff9f2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66814f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
